{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of logistic ordinal regression (aka proportional odds) model\n",
    "https://github.com/fabianp/minirank/blob/master/minirank/logistic.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import metrics\n",
    "from scipy import linalg, optimize, sparse, stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "BIG = 1e10\n",
    "SMALL = 1e-12\n",
    "\n",
    "\n",
    "def phi(t):\n",
    "    \"\"\"\n",
    "    logistic function, returns 1 / (1 + exp(-t))\n",
    "    \"\"\"\n",
    "    idx = t > 0\n",
    "    out = np.empty(t.size, dtype=np.float)\n",
    "    out[idx] = 1. / (1 + np.exp(-t[idx]))\n",
    "    exp_t = np.exp(t[~idx])\n",
    "    out[~idx] = exp_t / (1. + exp_t)\n",
    "    return out\n",
    "\n",
    "def log_logistic(t):\n",
    "    \"\"\"\n",
    "    (minus) logistic loss function, returns log(1 / (1 + exp(-t)))\n",
    "    \"\"\"\n",
    "    idx = t > 0\n",
    "    out = np.zeros_like(t)\n",
    "    out[idx] = np.log(1 + np.exp(-t[idx]))\n",
    "    out[~idx] = (-t[~idx] + np.log(1 + np.exp(t[~idx])))\n",
    "    return out\n",
    "\n",
    "\n",
    "def ordinal_logistic_fit(X, y, alpha=0, l1_ratio=0, n_class=None, max_iter=10000,\n",
    "                         verbose=False, solver='TNC', w0=None):\n",
    "    \"\"\"\n",
    "    Ordinal logistic regression or proportional odds model.\n",
    "    Uses scipy's optimize.fmin_slsqp solver.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array, sparse matrix}, shape (n_samples, n_feaures)\n",
    "        Input data\n",
    "    y : array-like\n",
    "        Target values\n",
    "    max_iter : int\n",
    "        Maximum number of iterations\n",
    "    verbose: bool\n",
    "        Print convergence information\n",
    "    Returns\n",
    "    -------\n",
    "    w : array, shape (n_features,)\n",
    "        coefficients of the linear model\n",
    "    theta : array, shape (k,), where k is the different values of y\n",
    "        vector of thresholds\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    w0 = None\n",
    "\n",
    "    if not X.shape[0] == y.shape[0]:\n",
    "        raise ValueError('Wrong shape for X and y')\n",
    "\n",
    "    # .. order input ..\n",
    "    idx = np.argsort(y)\n",
    "    idx_inv = np.zeros_like(idx)\n",
    "    idx_inv[idx] = np.arange(idx.size)\n",
    "    X = X[idx]\n",
    "    y = y[idx].astype(np.int)\n",
    "    # make them continuous and start at zero\n",
    "    unique_y = np.unique(y)\n",
    "    for i, u in enumerate(unique_y):\n",
    "        y[y == u] = i\n",
    "    unique_y = np.unique(y)\n",
    "\n",
    "    # .. utility arrays used in f_grad ..\n",
    "    alpha = 0.\n",
    "    k1 = np.sum(y == unique_y[0])\n",
    "    E0 = (y[:, np.newaxis] == np.unique(y)).astype(np.int)\n",
    "    E1 = np.roll(E0, -1, axis=-1)\n",
    "    E1[:, -1] = 0.\n",
    "    E0, E1 = map(sparse.csr_matrix, (E0.T, E1.T))\n",
    "\n",
    "    def f_obj(x0, X, y):\n",
    "        \"\"\"\n",
    "        Objective function\n",
    "        \"\"\"\n",
    "        w, theta_0 = np.split(x0, [X.shape[1]])\n",
    "        theta_1 = np.roll(theta_0, 1)\n",
    "        t0 = theta_0[y]\n",
    "        z = np.diff(theta_0)\n",
    "\n",
    "        Xw = X.dot(w)\n",
    "        a = t0 - Xw\n",
    "        b = t0[k1:] - X[k1:].dot(w)\n",
    "        c = (theta_1 - theta_0)[y][k1:]\n",
    "\n",
    "        if np.any(c > 0):\n",
    "            return BIG\n",
    "\n",
    "        #loss = -(c[idx] + np.log(np.exp(-c[idx]) - 1)).sum()\n",
    "        loss = -np.log(1 - np.exp(c)).sum()\n",
    "\n",
    "        loss += b.sum() + log_logistic(b).sum() \\\n",
    "            + log_logistic(a).sum() \\\n",
    "            + .5 * alpha * w.dot(w) - np.log(z).sum()  # penalty\n",
    "        if np.isnan(loss):\n",
    "            pass\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "        return loss\n",
    "\n",
    "    def f_grad(x0, X, y):\n",
    "        \"\"\"\n",
    "        Gradient of the objective function\n",
    "        \"\"\"\n",
    "        w, theta_0 = np.split(x0, [X.shape[1]])\n",
    "        theta_1 = np.roll(theta_0, 1)\n",
    "        t0 = theta_0[y]\n",
    "        t1 = theta_1[y]\n",
    "        z = np.diff(theta_0)\n",
    "\n",
    "        Xw = X.dot(w)\n",
    "        a = t0 - Xw\n",
    "        b = t0[k1:] - X[k1:].dot(w)\n",
    "        c = (theta_1 - theta_0)[y][k1:]\n",
    "\n",
    "        # gradient for w\n",
    "        phi_a = phi(a)\n",
    "        phi_b = phi(b)\n",
    "        grad_w = -X[k1:].T.dot(phi_b) + X.T.dot(1 - phi_a) + alpha * w\n",
    "\n",
    "        # gradient for theta\n",
    "        idx = c > 0\n",
    "        tmp = np.empty_like(c)\n",
    "        tmp[idx] = 1. / (np.exp(-c[idx]) - 1)\n",
    "        tmp[~idx] = np.exp(c[~idx]) / (1 - np.exp(c[~idx])) # should not need\n",
    "        grad_theta = (E1 - E0)[:, k1:].dot(tmp) \\\n",
    "            + E0[:, k1:].dot(phi_b) - E0.dot(1 - phi_a)\n",
    "\n",
    "        grad_theta[:-1] += 1. / np.diff(theta_0)\n",
    "        grad_theta[1:] -= 1. / np.diff(theta_0)\n",
    "        out = np.concatenate((grad_w, grad_theta))\n",
    "        return out\n",
    "\n",
    "    def f_hess(x0, s, X, y):\n",
    "        x0 = np.asarray(x0)\n",
    "        w, theta_0 = np.split(x0, [X.shape[1]])\n",
    "        theta_1 = np.roll(theta_0, 1)\n",
    "        t0 = theta_0[y]\n",
    "        t1 = theta_1[y]\n",
    "        z = np.diff(theta_0)\n",
    "\n",
    "        Xw = X.dot(w)\n",
    "        a = t0 - Xw\n",
    "        b = t0[k1:] - X[k1:].dot(w)\n",
    "        c = (theta_1 - theta_0)[y][k1:]\n",
    "\n",
    "        D = np.diag(phi(a) * (1 - phi(a)))\n",
    "        D_= np.diag(phi(b) * (1 - phi(b)))\n",
    "        D1 = np.diag(np.exp(-c) / (np.exp(-c) - 1) ** 2)\n",
    "        Ex = (E1 - E0)[:, k1:].toarray()\n",
    "        Ex0 = E0.toarray()\n",
    "        H_A = X[k1:].T.dot(D_).dot(X[k1:]) + X.T.dot(D).dot(X)\n",
    "        H_C = - X[k1:].T.dot(D_).dot(E0[:, k1:].T.toarray()) \\\n",
    "            - X.T.dot(D).dot(E0.T.toarray())\n",
    "        H_B = Ex.dot(D1).dot(Ex.T) + Ex0[:, k1:].dot(D_).dot(Ex0[:, k1:].T) \\\n",
    "            - Ex0.dot(D).dot(Ex0.T)\n",
    "\n",
    "        p_w = H_A.shape[0]\n",
    "        tmp0 = H_A.dot(s[:p_w]) + H_C.dot(s[p_w:])\n",
    "        tmp1 = H_C.T.dot(s[:p_w]) + H_B.dot(s[p_w:])\n",
    "        return np.concatenate((tmp0, tmp1))\n",
    "\n",
    "        import ipdb; ipdb.set_trace()\n",
    "        import pylab as pl\n",
    "        pl.matshow(H_B)\n",
    "        pl.colorbar()\n",
    "        pl.title('True')\n",
    "        import numdifftools as nd\n",
    "        Hess = nd.Hessian(lambda x: f_obj(x, X, y))\n",
    "        H = Hess(x0)\n",
    "        pl.matshow(H[H_A.shape[0]:, H_A.shape[0]:])\n",
    "        #pl.matshow()\n",
    "        pl.title('estimated')\n",
    "        pl.colorbar()\n",
    "        pl.show()\n",
    "\n",
    "\n",
    "    def grad_hess(x0, X, y):\n",
    "        grad = f_grad(x0, X, y)\n",
    "        hess = lambda x: f_hess(x0, x, X, y)\n",
    "        return grad, hess\n",
    "\n",
    "    x0 = np.random.randn(X.shape[1] + unique_y.size) / X.shape[1]\n",
    "    if w0 is not None:\n",
    "        x0[:X.shape[1]] = w0\n",
    "    else:\n",
    "        x0[:X.shape[1]] = 0.\n",
    "    x0[X.shape[1]:] = np.sort(unique_y.size * np.random.rand(unique_y.size))\n",
    "\n",
    "    #print('Check grad: %s' % optimize.check_grad(f_obj, f_grad, x0, X, y))\n",
    "    #print(optimize.approx_fprime(x0, f_obj, 1e-6, X, y))\n",
    "    #print(f_grad(x0, X, y))\n",
    "    #print(optimize.approx_fprime(x0, f_obj, 1e-6, X, y) - f_grad(x0, X, y))\n",
    "    #import ipdb; ipdb.set_trace()\n",
    "\n",
    "    def callback(x0):\n",
    "        x0 = np.asarray(x0)\n",
    "        # print('Check grad: %s' % optimize.check_grad(f_obj, f_grad, x0, X, y))\n",
    "        if verbose:\n",
    "        # check that gradient is correctly computed\n",
    "            print('OBJ: %s' % f_obj(x0, X, y))\n",
    "\n",
    "    if solver == 'TRON':\n",
    "        import pytron\n",
    "        out = pytron.minimize(f_obj, grad_hess, x0, args=(X, y))\n",
    "    else:\n",
    "        options = {'maxiter' : max_iter, 'disp': 0, 'maxfun':10000}\n",
    "        out = optimize.minimize(f_obj, x0, args=(X, y), method=solver,\n",
    "            jac=f_grad, hessp=f_hess, options=options, callback=callback)\n",
    "\n",
    "    if not out.success:\n",
    "        warnings.warn(out.message)\n",
    "    w, theta = np.split(out.x, [X.shape[1]])\n",
    "    return w, theta\n",
    "\n",
    "\n",
    "def ordinal_logistic_predict(w, theta, X):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : coefficients obtained by ordinal_logistic\n",
    "    theta : thresholds\n",
    "    \"\"\"\n",
    "    unique_theta = np.sort(np.unique(theta))\n",
    "    out = X.dot(w)\n",
    "    unique_theta[-1] = np.inf # p(y <= max_level) = 1\n",
    "    tmp = out[:, None].repeat(unique_theta.size, axis=1)\n",
    "    return np.argmax(tmp < unique_theta, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "musicSubset = pd.read_csv('musicSubset.csv',sep=\",\",header='infer')\n",
    "clusterDF = musicSubset.ix[:, 12:28].copy()\n",
    "decade = musicSubset.ix[:, 9].copy()\n",
    "decadeRank = (decade/10)-196\n",
    "decadeRank = decadeRank.astype('int')\n",
    "clusterDF = clusterDF.as_matrix()\n",
    "decadeRank = decadeRank.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decadeRank.dtypes\n",
    "d = decadeRank.as_matrix()\n",
    "type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import cross_validation, datasets\n",
    "boston = datasets.load_boston()\n",
    "X, y = boston.data, np.round(boston.target)\n",
    "type(y)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:389: RuntimeWarning: Method TNC does not use Hessian-vector product information (hessp).\n",
      "  'information (hessp).' % method, RuntimeWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:221: OptimizeWarning: Unknown solver options: maxfun\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJ: 37838.5919205\n",
      "OBJ: 35143.8846301\n",
      "OBJ: 31622.448176\n",
      "OBJ: 30903.7795821\n",
      "OBJ: 30632.5555518\n",
      "OBJ: 29748.0639913\n",
      "OBJ: 29552.8369864\n",
      "OBJ: 29536.0013774\n",
      "OBJ: 29533.8705758\n",
      "OBJ: 29532.5808261\n",
      "OBJ: 29532.4682873\n",
      "OBJ: 29532.4676692\n",
      "OBJ: 29532.4676648\n",
      "OBJ: 29532.4676408\n",
      "OBJ: 29532.4676405\n",
      "OBJ: 29532.4676405\n",
      "ERROR (ORDINAL)  fold 1: 1.05964912281\n",
      "ERROR (LOGISTIC) fold 1: 1.11052631579\n",
      "ERROR (RIDGE)    fold 1: 1.03625730994\n",
      "OBJ: 32432.7149432\n",
      "OBJ: 30998.9019749\n",
      "OBJ: 29875.7654616\n",
      "OBJ: 29645.4914858\n",
      "OBJ: 29556.2704494\n",
      "OBJ: 29546.1695031\n",
      "OBJ: 29546.1542278\n",
      "OBJ: 29546.1074982\n",
      "OBJ: 29546.1062741\n",
      "OBJ: 29546.1060154\n",
      "OBJ: 29546.106009\n",
      "OBJ: 29546.1059991\n",
      "OBJ: 29546.1059985\n",
      "OBJ: 29546.1059984\n",
      "OBJ: 29546.1059984\n",
      "ERROR (ORDINAL)  fold 2: 1.08596491228\n",
      "ERROR (LOGISTIC) fold 2: 1.08947368421\n",
      "ERROR (RIDGE)    fold 2: 1.05204678363\n",
      "OBJ: 34245.0630217\n",
      "OBJ: 31371.4217629\n",
      "OBJ: 30807.8903487\n",
      "OBJ: 29861.873727\n",
      "OBJ: 29846.8840375\n",
      "OBJ: 29637.1948343\n",
      "OBJ: 29551.600447\n",
      "OBJ: 29545.3608235\n",
      "OBJ: 29544.9948044\n",
      "OBJ: 29544.9905596\n",
      "OBJ: 29544.964114\n",
      "OBJ: 29544.9639952\n",
      "OBJ: 29544.9639942\n",
      "OBJ: 29544.9639884\n",
      "OBJ: 29544.9639863\n",
      "OBJ: 29544.9639862\n",
      "OBJ: 29544.9639862\n",
      "ERROR (ORDINAL)  fold 3: 1.03567251462\n",
      "ERROR (LOGISTIC) fold 3: 1.09473684211\n",
      "ERROR (RIDGE)    fold 3: 1.02222222222\n",
      "OBJ: 40835.4959753\n",
      "OBJ: 34006.2667196\n",
      "OBJ: 31510.7312793\n",
      "OBJ: 30905.6511799\n",
      "OBJ: 29859.610622\n",
      "OBJ: 29551.6071322\n",
      "OBJ: 29526.6022565\n",
      "OBJ: 29525.637466\n",
      "OBJ: 29525.6260448\n",
      "OBJ: 29525.5814947\n",
      "OBJ: 29525.5810158\n",
      "OBJ: 29525.5809437\n",
      "OBJ: 29525.5808966\n",
      "OBJ: 29525.5808953\n",
      "OBJ: 29525.5808953\n",
      "ERROR (ORDINAL)  fold 4: 1.08947368421\n",
      "ERROR (LOGISTIC) fold 4: 1.1514619883\n",
      "ERROR (RIDGE)    fold 4: 1.07777777778\n",
      "OBJ: 37191.8364397\n",
      "OBJ: 33546.477348\n",
      "OBJ: 32200.2398462\n",
      "OBJ: 30150.3856479\n",
      "OBJ: 29743.9770573\n",
      "OBJ: 29712.4841538\n",
      "OBJ: 29584.1956554\n",
      "OBJ: 29573.5424092\n",
      "OBJ: 29571.7749787\n",
      "OBJ: 29571.6957503\n",
      "OBJ: 29571.6660585\n",
      "OBJ: 29571.6657257\n",
      "OBJ: 29571.6657114\n",
      "OBJ: 29571.6657109\n",
      "OBJ: 29571.6657109\n",
      "OBJ: 29571.6657109\n",
      "ERROR (ORDINAL)  fold 5: 0.978947368421\n",
      "ERROR (LOGISTIC) fold 5: 1.05847953216\n",
      "ERROR (RIDGE)    fold 5: 0.981871345029\n",
      "OBJ: 31209.8541792\n",
      "OBJ: 29902.3639787\n",
      "OBJ: 29793.4543136\n",
      "OBJ: 29531.3390177\n",
      "OBJ: 29521.3238384\n",
      "OBJ: 29521.0631824\n",
      "OBJ: 29521.0539167\n",
      "OBJ: 29521.053459\n",
      "OBJ: 29521.0533445\n",
      "OBJ: 29521.0532939\n",
      "OBJ: 29521.0532927\n",
      "OBJ: 29521.0532926\n",
      "OBJ: 29521.0532926\n",
      "ERROR (ORDINAL)  fold 6: 1.06900584795\n",
      "ERROR (LOGISTIC) fold 6: 1.13040935673\n",
      "ERROR (RIDGE)    fold 6: 1.05497076023\n",
      "OBJ: 33946.5125432\n",
      "OBJ: 30602.9641512\n",
      "OBJ: 29911.3478527\n",
      "OBJ: 29654.1143234\n",
      "OBJ: 29640.0436223\n",
      "OBJ: 29550.1920871\n",
      "OBJ: 29547.1053002\n",
      "OBJ: 29547.0937268\n",
      "OBJ: 29546.9881242\n",
      "OBJ: 29546.9614073\n",
      "OBJ: 29546.9605843\n",
      "OBJ: 29546.9604862\n",
      "OBJ: 29546.9604861\n",
      "OBJ: 29546.9604854\n",
      "OBJ: 29546.9604854\n",
      "OBJ: 29546.9604854\n",
      "ERROR (ORDINAL)  fold 7: 1.0298245614\n",
      "ERROR (LOGISTIC) fold 7: 1.08713450292\n",
      "ERROR (RIDGE)    fold 7: 1.03157894737\n",
      "OBJ: 32216.4008223\n",
      "OBJ: 31015.8582788\n",
      "OBJ: 29888.0789938\n",
      "OBJ: 29861.1548759\n",
      "OBJ: 29659.3733653\n",
      "OBJ: 29573.3782221\n",
      "OBJ: 29559.988397\n",
      "OBJ: 29558.0844438\n",
      "OBJ: 29558.0240759\n",
      "OBJ: 29558.0236024\n",
      "OBJ: 29558.0143338\n",
      "OBJ: 29558.0142449\n",
      "OBJ: 29558.014215\n",
      "OBJ: 29558.0142148\n",
      "OBJ: 29558.0142141\n",
      "OBJ: 29558.0142138\n",
      "OBJ: 29558.0142138\n",
      "OBJ: 29558.0142138\n",
      "ERROR (ORDINAL)  fold 8: 1.06023391813\n",
      "ERROR (LOGISTIC) fold 8: 1.10467836257\n",
      "ERROR (RIDGE)    fold 8: 1.04152046784\n",
      "OBJ: 32679.895439\n",
      "OBJ: 30815.7841279\n",
      "OBJ: 29584.4914026\n",
      "OBJ: 29517.5954802\n",
      "OBJ: 29492.2032305\n",
      "OBJ: 29483.8487124\n",
      "OBJ: 29482.4080615\n",
      "OBJ: 29482.3698023\n",
      "OBJ: 29482.369695\n",
      "OBJ: 29482.3691419\n",
      "OBJ: 29482.3690223\n",
      "OBJ: 29482.3690186\n",
      "OBJ: 29482.3690185\n",
      "OBJ: 29482.3690185\n",
      "OBJ: 29482.3690185\n",
      "ERROR (ORDINAL)  fold 9: 1.02631578947\n",
      "ERROR (LOGISTIC) fold 9: 1.12456140351\n",
      "ERROR (RIDGE)    fold 9: 1.03099415205\n",
      "OBJ: 33826.7978783\n",
      "OBJ: 31147.2212783\n",
      "OBJ: 30883.5413898\n",
      "OBJ: 29852.1842206\n",
      "OBJ: 29567.6628585\n",
      "OBJ: 29547.4924554\n",
      "OBJ: 29541.5221025\n",
      "OBJ: 29540.8722586\n",
      "OBJ: 29540.6331839\n",
      "OBJ: 29540.6227623\n",
      "OBJ: 29540.6227506\n",
      "OBJ: 29540.622739\n",
      "OBJ: 29540.6227389\n",
      "OBJ: 29540.6227388\n",
      "ERROR (ORDINAL)  fold 10: 1.04502923977\n",
      "ERROR (LOGISTIC) fold 10: 1.0701754386\n",
      "ERROR (RIDGE)    fold 10: 1.03216374269\n",
      "OBJ: 33246.1335948\n",
      "OBJ: 31496.7638475\n",
      "OBJ: 30973.6427794\n",
      "OBJ: 30892.3268163\n",
      "OBJ: 29849.0743889\n",
      "OBJ: 29589.0359961\n",
      "OBJ: 29565.8771575\n",
      "OBJ: 29559.3767336\n",
      "OBJ: 29559.048603\n",
      "OBJ: 29558.9564815\n",
      "OBJ: 29558.9535929\n",
      "OBJ: 29558.9535067\n",
      "OBJ: 29558.9532647\n",
      "OBJ: 29558.9532618\n",
      "OBJ: 29558.953261\n",
      "OBJ: 29558.953261\n",
      "ERROR (ORDINAL)  fold 11: 1.01228070175\n",
      "ERROR (LOGISTIC) fold 11: 1.10058479532\n",
      "ERROR (RIDGE)    fold 11: 0.997076023392\n",
      "OBJ: 33835.7920399\n",
      "OBJ: 31166.3053963\n",
      "OBJ: 30750.1832168\n",
      "OBJ: 29851.4373114\n",
      "OBJ: 29594.9726018\n",
      "OBJ: 29571.9639923\n",
      "OBJ: 29571.24147\n",
      "OBJ: 29571.2333094\n",
      "OBJ: 29571.1866183\n",
      "OBJ: 29571.1857853\n",
      "OBJ: 29571.1855713\n",
      "OBJ: 29571.1855527\n",
      "OBJ: 29571.1855525\n",
      "OBJ: 29571.1855525\n",
      "OBJ: 29571.1855525\n",
      "ERROR (ORDINAL)  fold 12: 1.04152046784\n",
      "ERROR (LOGISTIC) fold 12: 1.05087719298\n",
      "ERROR (RIDGE)    fold 12: 1.02573099415\n",
      "OBJ: 34812.3491922\n",
      "OBJ: 31192.2998564\n",
      "OBJ: 30891.2494186\n",
      "OBJ: 29901.0810558\n",
      "OBJ: 29674.2273707\n",
      "OBJ: 29580.2036457\n",
      "OBJ: 29574.9265211\n",
      "OBJ: 29574.7063158\n",
      "OBJ: 29574.6726957\n",
      "OBJ: 29574.672139\n",
      "OBJ: 29574.6719179\n",
      "OBJ: 29574.6718683\n",
      "OBJ: 29574.6718669\n",
      "OBJ: 29574.6718667\n",
      "OBJ: 29574.6718666\n",
      "OBJ: 29574.6718666\n",
      "ERROR (ORDINAL)  fold 13: 1.03216374269\n",
      "ERROR (LOGISTIC) fold 13: 1.07602339181\n",
      "ERROR (RIDGE)    fold 13: 1.00116959064\n",
      "OBJ: 32813.0672747\n",
      "OBJ: 30863.4038592\n",
      "OBJ: 29863.9615376\n",
      "OBJ: 29650.3028738\n",
      "OBJ: 29570.924573\n",
      "OBJ: 29562.0558034\n",
      "OBJ: 29561.9615995\n",
      "OBJ: 29561.957668\n",
      "OBJ: 29561.948843\n",
      "OBJ: 29561.9486276\n",
      "OBJ: 29561.9486143\n",
      "OBJ: 29561.9486142\n",
      "OBJ: 29561.9486142\n",
      "OBJ: 29561.9486142\n",
      "ERROR (ORDINAL)  fold 14: 1.02573099415\n",
      "ERROR (LOGISTIC) fold 14: 1.08771929825\n",
      "ERROR (RIDGE)    fold 14: 1.04444444444\n",
      "OBJ: 43182.0749553\n",
      "OBJ: 34717.9870023\n",
      "OBJ: 31958.122173\n",
      "OBJ: 31016.6728462\n",
      "OBJ: 30945.0799704\n",
      "OBJ: 29856.5203737\n",
      "OBJ: 29582.784315\n",
      "OBJ: 29566.0684051\n",
      "OBJ: 29555.967104\n",
      "OBJ: 29554.9486633\n",
      "OBJ: 29554.9233834\n",
      "OBJ: 29554.9232505\n",
      "OBJ: 29554.9221128\n",
      "OBJ: 29554.9220803\n",
      "OBJ: 29554.9220787\n",
      "OBJ: 29554.9220786\n",
      "OBJ: 29554.9220782\n",
      "OBJ: 29554.9220782\n",
      "ERROR (ORDINAL)  fold 15: 1.04970760234\n",
      "ERROR (LOGISTIC) fold 15: 1.10584795322\n",
      "ERROR (RIDGE)    fold 15: 1.03625730994\n",
      "OBJ: 33617.8216039\n",
      "OBJ: 31357.7184473\n",
      "OBJ: 30785.88525\n",
      "OBJ: 29651.5097008\n",
      "OBJ: 29612.9434678\n",
      "OBJ: 29606.8306009\n",
      "OBJ: 29606.2188372\n",
      "OBJ: 29606.2138265\n",
      "OBJ: 29606.1786861\n",
      "OBJ: 29606.1783835\n",
      "OBJ: 29606.1783756\n",
      "OBJ: 29606.1783155\n",
      "OBJ: 29606.178315\n",
      "OBJ: 29606.178315\n",
      "OBJ: 29606.178315\n",
      "ERROR (ORDINAL)  fold 16: 1.05497076023\n",
      "ERROR (LOGISTIC) fold 16: 1.0783625731\n",
      "ERROR (RIDGE)    fold 16: 1.03625730994\n",
      "OBJ: 45510.6141104\n",
      "OBJ: 31648.8225968\n",
      "OBJ: 30940.7884846\n",
      "OBJ: 29656.3445361\n",
      "OBJ: 29621.4102919\n",
      "OBJ: 29573.8953451\n",
      "OBJ: 29561.3651619\n",
      "OBJ: 29559.9386134\n",
      "OBJ: 29559.6717492\n",
      "OBJ: 29559.6709802\n",
      "OBJ: 29559.6535389\n",
      "OBJ: 29559.6521498\n",
      "OBJ: 29559.6520418\n",
      "OBJ: 29559.6520245\n",
      "OBJ: 29559.652021\n",
      "OBJ: 29559.652021\n",
      "OBJ: 29559.6520209\n",
      "ERROR (ORDINAL)  fold 17: 1.01461988304\n",
      "ERROR (LOGISTIC) fold 17: 1.09824561404\n",
      "ERROR (RIDGE)    fold 17: 1.01461988304\n",
      "OBJ: 34714.5148466\n",
      "OBJ: 32843.7573452\n",
      "OBJ: 31044.9167638\n",
      "OBJ: 29596.2092091\n",
      "OBJ: 29564.8260366\n",
      "OBJ: 29526.2604117\n",
      "OBJ: 29516.0818919\n",
      "OBJ: 29514.3019571\n",
      "OBJ: 29514.2969693\n",
      "OBJ: 29514.0222866\n",
      "OBJ: 29513.9990151\n",
      "OBJ: 29513.9978702\n",
      "OBJ: 29513.9975913\n",
      "OBJ: 29513.9975907\n",
      "OBJ: 29513.9975887\n",
      "OBJ: 29513.9975883\n",
      "OBJ: 29513.9975883\n",
      "OBJ: 29513.9975883\n",
      "ERROR (ORDINAL)  fold 18: 1.03801169591\n",
      "ERROR (LOGISTIC) fold 18: 1.09590643275\n",
      "ERROR (RIDGE)    fold 18: 1.00643274854\n",
      "OBJ: 37675.4976949\n",
      "OBJ: 32757.8657017\n",
      "OBJ: 31397.0273136\n",
      "OBJ: 30941.0652686\n",
      "OBJ: 29875.8195872\n",
      "OBJ: 29574.6736531\n",
      "OBJ: 29546.4378258\n",
      "OBJ: 29546.2552202\n",
      "OBJ: 29545.5060275\n",
      "OBJ: 29545.2632619\n",
      "OBJ: 29545.2496253\n",
      "OBJ: 29545.2483996\n",
      "OBJ: 29545.2483852\n",
      "OBJ: 29545.2483366\n",
      "OBJ: 29545.2483347\n",
      "OBJ: 29545.2483347\n",
      "OBJ: 29545.2483345\n",
      "OBJ: 29545.2483345\n",
      "OBJ: 29545.2483345\n",
      "ERROR (ORDINAL)  fold 19: 1.0514619883\n",
      "ERROR (LOGISTIC) fold 19: 1.08070175439\n",
      "ERROR (RIDGE)    fold 19: 1.03625730994\n",
      "OBJ: 39021.1832783\n",
      "OBJ: 32676.1981578\n",
      "OBJ: 30975.8997633\n",
      "OBJ: 30611.1533834\n",
      "OBJ: 29730.1813541\n",
      "OBJ: 29575.0012752\n",
      "OBJ: 29560.8892067\n",
      "OBJ: 29559.7331757\n",
      "OBJ: 29559.2488452\n",
      "OBJ: 29559.2135479\n",
      "OBJ: 29559.2130285\n",
      "OBJ: 29559.2129803\n",
      "OBJ: 29559.2128666\n",
      "OBJ: 29559.2128657\n",
      "OBJ: 29559.2128655\n",
      "OBJ: 29559.2128655\n",
      "ERROR (ORDINAL)  fold 20: 1.06140350877\n",
      "ERROR (LOGISTIC) fold 20: 1.08245614035\n",
      "ERROR (RIDGE)    fold 20: 1.04912280702\n",
      "OBJ: 37660.3902667\n",
      "OBJ: 32173.0818915\n",
      "OBJ: 31152.329077\n",
      "OBJ: 30939.2065606\n",
      "OBJ: 29918.8941265\n",
      "OBJ: 29612.0415656\n",
      "OBJ: 29585.6592441\n",
      "OBJ: 29585.1948563\n",
      "OBJ: 29585.1798998\n",
      "OBJ: 29585.1299899\n",
      "OBJ: 29585.1199\n",
      "OBJ: 29585.1196463\n",
      "OBJ: 29585.119643\n",
      "OBJ: 29585.1196326\n",
      "OBJ: 29585.1196325\n",
      "OBJ: 29585.1196325\n",
      "OBJ: 29585.1196325\n",
      "ERROR (ORDINAL)  fold 21: 1.01461988304\n",
      "ERROR (LOGISTIC) fold 21: 1.0730994152\n",
      "ERROR (RIDGE)    fold 21: 1.01637426901\n",
      "OBJ: 35533.560313\n",
      "OBJ: 32843.399167\n",
      "OBJ: 30930.0651022\n",
      "OBJ: 29844.398809\n",
      "OBJ: 29584.3724934\n",
      "OBJ: 29567.8236977\n",
      "OBJ: 29555.5186502\n",
      "OBJ: 29549.0844557\n",
      "OBJ: 29548.4133991\n",
      "OBJ: 29548.3953865\n",
      "OBJ: 29548.3938722\n",
      "OBJ: 29548.3936874\n",
      "OBJ: 29548.3936831\n",
      "OBJ: 29548.3936831\n",
      "OBJ: 29548.393683\n",
      "OBJ: 29548.393683\n",
      "ERROR (ORDINAL)  fold 22: 1.03391812865\n",
      "ERROR (LOGISTIC) fold 22: 1.06842105263\n",
      "ERROR (RIDGE)    fold 22: 1.0350877193\n",
      "OBJ: 35714.8512765\n",
      "OBJ: 33853.9392661\n",
      "OBJ: 30441.7350233\n",
      "OBJ: 29914.658969\n",
      "OBJ: 29877.7669558\n",
      "OBJ: 29637.9232789\n",
      "OBJ: 29592.0299403\n",
      "OBJ: 29588.6323055\n",
      "OBJ: 29588.3538227\n",
      "OBJ: 29588.3502918\n",
      "OBJ: 29588.3169828\n",
      "OBJ: 29588.3166685\n",
      "OBJ: 29588.3166675\n",
      "OBJ: 29588.3166662\n",
      "OBJ: 29588.3166661\n",
      "OBJ: 29588.3166661\n",
      "ERROR (ORDINAL)  fold 23: 1.02339181287\n",
      "ERROR (LOGISTIC) fold 23: 1.05789473684\n",
      "ERROR (RIDGE)    fold 23: 1.02514619883\n",
      "OBJ: 38684.6824057\n",
      "OBJ: 32916.7964639\n",
      "OBJ: 30986.9706364\n",
      "OBJ: 30863.4003348\n",
      "OBJ: 29873.8686849\n",
      "OBJ: 29620.4971447\n",
      "OBJ: 29591.7852978\n",
      "OBJ: 29591.6508625\n",
      "OBJ: 29589.6711269\n",
      "OBJ: 29588.7549597\n",
      "OBJ: 29588.7321794\n",
      "OBJ: 29588.7285945\n",
      "OBJ: 29588.7285818\n",
      "OBJ: 29588.7285165\n",
      "OBJ: 29588.7285028\n",
      "OBJ: 29588.7285028\n",
      "ERROR (ORDINAL)  fold 24: 1.03040935673\n",
      "ERROR (LOGISTIC) fold 24: 1.06900584795\n",
      "ERROR (RIDGE)    fold 24: 1.01637426901\n",
      "OBJ: 32129.2723532\n",
      "OBJ: 30961.0755131\n",
      "OBJ: 30715.9839164\n",
      "OBJ: 29844.4895123\n",
      "OBJ: 29832.6166174\n",
      "OBJ: 29606.515415\n",
      "OBJ: 29538.4657832\n",
      "OBJ: 29531.3472208\n",
      "OBJ: 29531.0053896\n",
      "OBJ: 29531.0034693\n",
      "OBJ: 29530.9750453\n",
      "OBJ: 29530.9708381\n",
      "OBJ: 29530.9707358\n",
      "OBJ: 29530.9707345\n",
      "OBJ: 29530.9707318\n",
      "OBJ: 29530.9707317\n",
      "OBJ: 29530.9707317\n",
      "OBJ: 29530.9707317\n",
      "ERROR (ORDINAL)  fold 25: 1.03859649123\n",
      "ERROR (LOGISTIC) fold 25: 1.0865497076\n",
      "ERROR (RIDGE)    fold 25: 1.01578947368\n",
      "OBJ: 41763.1129707\n",
      "OBJ: 38770.7395741\n",
      "OBJ: 33257.1062642\n",
      "OBJ: 30348.8291226\n",
      "OBJ: 29933.2723571\n",
      "OBJ: 29579.0567661\n",
      "OBJ: 29564.8589846\n",
      "OBJ: 29555.5433464\n",
      "OBJ: 29554.506859\n",
      "OBJ: 29554.4090844\n",
      "OBJ: 29554.4084721\n",
      "OBJ: 29554.4033305\n",
      "OBJ: 29554.4032661\n",
      "OBJ: 29554.4032629\n",
      "OBJ: 29554.4032493\n",
      "OBJ: 29554.4032492\n",
      "OBJ: 29554.4032492\n",
      "ERROR (ORDINAL)  fold 26: 1.05497076023\n",
      "ERROR (LOGISTIC) fold 26: 1.07719298246\n",
      "ERROR (RIDGE)    fold 26: 1.02865497076\n",
      "OBJ: 33697.0987767\n",
      "OBJ: 31687.7423222\n",
      "OBJ: 30995.9005509\n",
      "OBJ: 30876.6784496\n",
      "OBJ: 29866.6389187\n",
      "OBJ: 29555.892413\n",
      "OBJ: 29534.0263218\n",
      "OBJ: 29533.5315454\n",
      "OBJ: 29533.5200767\n",
      "OBJ: 29533.4779798\n",
      "OBJ: 29533.4736353\n",
      "OBJ: 29533.4736308\n",
      "OBJ: 29533.473581\n",
      "OBJ: 29533.4735745\n",
      "OBJ: 29533.4735745\n",
      "OBJ: 29533.4735744\n",
      "OBJ: 29533.4735744\n",
      "ERROR (ORDINAL)  fold 27: 1.05087719298\n",
      "ERROR (LOGISTIC) fold 27: 1.11286549708\n",
      "ERROR (RIDGE)    fold 27: 1.0432748538\n",
      "OBJ: 32656.6901245\n",
      "OBJ: 30941.2930895\n",
      "OBJ: 29897.9569737\n",
      "OBJ: 29595.1291026\n",
      "OBJ: 29574.0375367\n",
      "OBJ: 29561.5213277\n",
      "OBJ: 29560.0319497\n",
      "OBJ: 29560.0192057\n",
      "OBJ: 29560.018461\n",
      "OBJ: 29560.016929\n",
      "OBJ: 29560.0169254\n",
      "OBJ: 29560.0169231\n",
      "OBJ: 29560.0169228\n",
      "OBJ: 29560.0169228\n",
      "ERROR (ORDINAL)  fold 28: 1.01461988304\n",
      "ERROR (LOGISTIC) fold 28: 1.06023391813\n",
      "ERROR (RIDGE)    fold 28: 1.01461988304\n",
      "OBJ: 32472.305333\n",
      "OBJ: 30107.7006787\n",
      "OBJ: 29825.8973797\n",
      "OBJ: 29643.5185496\n",
      "OBJ: 29574.3675958\n",
      "OBJ: 29565.4592681\n",
      "OBJ: 29564.6049473\n",
      "OBJ: 29564.5642035\n",
      "OBJ: 29564.5631396\n",
      "OBJ: 29564.559847\n",
      "OBJ: 29564.5597688\n",
      "OBJ: 29564.5597541\n",
      "OBJ: 29564.5597506\n",
      "OBJ: 29564.5597505\n",
      "OBJ: 29564.5597505\n",
      "OBJ: 29564.5597505\n",
      "ERROR (ORDINAL)  fold 29: 1.02456140351\n",
      "ERROR (LOGISTIC) fold 29: 1.05789473684\n",
      "ERROR (RIDGE)    fold 29: 1.01812865497\n",
      "OBJ: 36908.0174392\n",
      "OBJ: 30795.8232482\n",
      "OBJ: 30528.4847545\n",
      "OBJ: 29785.3631751\n",
      "OBJ: 29558.5404457\n",
      "OBJ: 29543.9744504\n",
      "OBJ: 29541.0667324\n",
      "OBJ: 29541.0170016\n",
      "OBJ: 29540.9073955\n",
      "OBJ: 29540.8880482\n",
      "OBJ: 29540.8876902\n",
      "OBJ: 29540.8876808\n",
      "OBJ: 29540.8876666\n",
      "OBJ: 29540.8876664\n",
      "OBJ: 29540.8876664\n",
      "ERROR (ORDINAL)  fold 30: 1.01695906433\n",
      "ERROR (LOGISTIC) fold 30: 1.0865497076\n",
      "ERROR (RIDGE)    fold 30: 0.99298245614\n",
      "OBJ: 39301.3475138\n",
      "OBJ: 33956.3596083\n",
      "OBJ: 32048.7280747\n",
      "OBJ: 31050.0218561\n",
      "OBJ: 30881.2748022\n",
      "OBJ: 29794.9853614\n",
      "OBJ: 29562.7760437\n",
      "OBJ: 29541.4550212\n",
      "OBJ: 29541.2372018\n",
      "OBJ: 29537.9325475\n",
      "OBJ: 29535.8917844\n",
      "OBJ: 29535.7835135\n",
      "OBJ: 29535.7592578\n",
      "OBJ: 29535.7582198\n",
      "OBJ: 29535.7582135\n",
      "OBJ: 29535.7581648\n",
      "OBJ: 29535.7581561\n",
      "OBJ: 29535.7581558\n",
      "OBJ: 29535.7581558\n",
      "ERROR (ORDINAL)  fold 31: 1.03976608187\n",
      "ERROR (LOGISTIC) fold 31: 1.08538011696\n",
      "ERROR (RIDGE)    fold 31: 1.01461988304\n",
      "OBJ: 38899.5993832\n",
      "OBJ: 33585.5698912\n",
      "OBJ: 31605.1842684\n",
      "OBJ: 30967.1019484\n",
      "OBJ: 30819.4071868\n",
      "OBJ: 29837.2765181\n",
      "OBJ: 29557.3589908\n",
      "OBJ: 29529.5859721\n",
      "OBJ: 29520.5930598\n",
      "OBJ: 29519.9535448\n",
      "OBJ: 29519.9475641\n",
      "OBJ: 29519.881555\n",
      "OBJ: 29519.8801469\n",
      "OBJ: 29519.8798291\n",
      "OBJ: 29519.879828\n",
      "OBJ: 29519.879815\n",
      "OBJ: 29519.8798149\n",
      "OBJ: 29519.8798148\n",
      "OBJ: 29519.8798148\n",
      "ERROR (ORDINAL)  fold 32: 1.03567251462\n",
      "ERROR (LOGISTIC) fold 32: 1.11754385965\n",
      "ERROR (RIDGE)    fold 32: 1.03274853801\n",
      "OBJ: 39360.355789\n",
      "OBJ: 35653.4262046\n",
      "OBJ: 33060.5113667\n",
      "OBJ: 31197.0308283\n",
      "OBJ: 30991.3798783\n",
      "OBJ: 29931.8857878\n",
      "OBJ: 29581.5978915\n",
      "OBJ: 29557.9189877\n",
      "OBJ: 29557.8093441\n",
      "OBJ: 29552.1468806\n",
      "OBJ: 29551.9517243\n",
      "OBJ: 29551.9489525\n",
      "OBJ: 29551.9486788\n",
      "OBJ: 29551.9482851\n",
      "OBJ: 29551.9482831\n",
      "OBJ: 29551.948283\n",
      "OBJ: 29551.948283\n",
      "ERROR (ORDINAL)  fold 33: 1.05380116959\n",
      "ERROR (LOGISTIC) fold 33: 1.08421052632\n",
      "ERROR (RIDGE)    fold 33: 1.04619883041\n",
      "OBJ: 37104.3931181\n",
      "OBJ: 35167.9697875\n",
      "OBJ: 32216.9093882\n",
      "OBJ: 31188.7680167\n",
      "OBJ: 30933.3775147\n",
      "OBJ: 29936.1851752\n",
      "OBJ: 29579.9747203\n",
      "OBJ: 29564.384948\n",
      "OBJ: 29564.2340652\n",
      "OBJ: 29561.7202396\n",
      "OBJ: 29561.6676758\n",
      "OBJ: 29561.6676535\n",
      "OBJ: 29561.6674246\n",
      "OBJ: 29561.6673566\n",
      "OBJ: 29561.6673503\n",
      "OBJ: 29561.6673503\n",
      "OBJ: 29561.6673502\n",
      "OBJ: 29561.6673502\n",
      "ERROR (ORDINAL)  fold 34: 1.03625730994\n",
      "ERROR (LOGISTIC) fold 34: 1.07368421053\n",
      "ERROR (RIDGE)    fold 34: 1.03333333333\n",
      "OBJ: 39353.5733987\n",
      "OBJ: 37169.6847725\n",
      "OBJ: 34460.1210987\n",
      "OBJ: 31902.3856323\n",
      "OBJ: 31093.7903674\n",
      "OBJ: 29859.6311062\n",
      "OBJ: 29589.7166108\n",
      "OBJ: 29574.1695825\n",
      "OBJ: 29573.9539546\n",
      "OBJ: 29571.1308226\n",
      "OBJ: 29570.028386\n",
      "OBJ: 29570.0032716\n",
      "OBJ: 29569.9961522\n",
      "OBJ: 29569.9958665\n",
      "OBJ: 29569.9958546\n",
      "OBJ: 29569.9958521\n",
      "OBJ: 29569.9958519\n",
      "OBJ: 29569.9958519\n",
      "OBJ: 29569.9958518\n",
      "ERROR (ORDINAL)  fold 35: 1.01871345029\n",
      "ERROR (LOGISTIC) fold 35: 1.09590643275\n",
      "ERROR (RIDGE)    fold 35: 1.03157894737\n",
      "OBJ: 31694.9347451\n",
      "OBJ: 30063.1922985\n",
      "OBJ: 29858.5362214\n",
      "OBJ: 29592.7471188\n",
      "OBJ: 29584.0490849\n",
      "OBJ: 29581.2561832\n",
      "OBJ: 29581.0121245\n",
      "OBJ: 29581.0081085\n",
      "OBJ: 29580.9988404\n",
      "OBJ: 29580.9985758\n",
      "OBJ: 29580.9985684\n",
      "OBJ: 29580.9985677\n",
      "OBJ: 29580.9985677\n",
      "ERROR (ORDINAL)  fold 36: 1.04912280702\n",
      "ERROR (LOGISTIC) fold 36: 1.03801169591\n",
      "ERROR (RIDGE)    fold 36: 1.01754385965\n",
      "OBJ: 36428.5704486\n",
      "OBJ: 31014.2204761\n",
      "OBJ: 30418.8214883\n",
      "OBJ: 30387.175636\n",
      "OBJ: 29744.8780673\n",
      "OBJ: 29574.5695256\n",
      "OBJ: 29562.555871\n",
      "OBJ: 29560.3366546\n",
      "OBJ: 29560.3118401\n",
      "OBJ: 29560.2021203\n",
      "OBJ: 29560.1986025\n",
      "OBJ: 29560.1979602\n",
      "OBJ: 29560.1979558\n",
      "OBJ: 29560.1979248\n",
      "OBJ: 29560.1979227\n",
      "OBJ: 29560.1979226\n",
      "OBJ: 29560.1979225\n",
      "OBJ: 29560.1979225\n",
      "ERROR (ORDINAL)  fold 37: 1.06959064327\n",
      "ERROR (LOGISTIC) fold 37: 1.14444444444\n",
      "ERROR (RIDGE)    fold 37: 1.05847953216\n",
      "OBJ: 35963.995718\n",
      "OBJ: 33888.4925879\n",
      "OBJ: 30534.5158583\n",
      "OBJ: 29944.8321991\n",
      "OBJ: 29877.0988172\n",
      "OBJ: 29554.5327123\n",
      "OBJ: 29551.4593001\n",
      "OBJ: 29551.4270061\n",
      "OBJ: 29551.4195899\n",
      "OBJ: 29551.4184201\n",
      "OBJ: 29551.4183916\n",
      "OBJ: 29551.4183899\n",
      "OBJ: 29551.418388\n",
      "OBJ: 29551.418388\n",
      "OBJ: 29551.4183879\n",
      "ERROR (ORDINAL)  fold 38: 1.04795321637\n",
      "ERROR (LOGISTIC) fold 38: 1.10935672515\n",
      "ERROR (RIDGE)    fold 38: 1.06081871345\n",
      "OBJ: 46360.1853823\n",
      "OBJ: 33241.314064\n",
      "OBJ: 30926.3728242\n",
      "OBJ: 30575.5988892\n",
      "OBJ: 29759.6143413\n",
      "OBJ: 29533.6243371\n",
      "OBJ: 29518.9127885\n",
      "OBJ: 29517.5272189\n",
      "OBJ: 29517.5250369\n",
      "OBJ: 29517.4620661\n",
      "OBJ: 29517.4618324\n",
      "OBJ: 29517.4618236\n",
      "OBJ: 29517.4617748\n",
      "OBJ: 29517.4617741\n",
      "OBJ: 29517.4617741\n",
      "ERROR (ORDINAL)  fold 39: 1.01111111111\n",
      "ERROR (LOGISTIC) fold 39: 1.06900584795\n",
      "ERROR (RIDGE)    fold 39: 1.01169590643\n",
      "OBJ: 40804.4651382\n",
      "OBJ: 34268.3351645\n",
      "OBJ: 31945.2598351\n",
      "OBJ: 31015.7833676\n",
      "OBJ: 30904.4487983\n",
      "OBJ: 29875.1396981\n",
      "OBJ: 29549.8925875\n",
      "OBJ: 29536.7909439\n",
      "OBJ: 29528.5443381\n",
      "OBJ: 29527.7530752\n",
      "OBJ: 29527.7335913\n",
      "OBJ: 29527.7335221\n",
      "OBJ: 29527.7332436\n",
      "OBJ: 29527.7332328\n",
      "OBJ: 29527.7332328\n",
      "OBJ: 29527.7332325\n",
      "OBJ: 29527.7332325\n",
      "ERROR (ORDINAL)  fold 40: 1.05380116959\n",
      "ERROR (LOGISTIC) fold 40: 1.08888888889\n",
      "ERROR (RIDGE)    fold 40: 1.04093567251\n",
      "OBJ: 39172.9570759\n",
      "OBJ: 32302.0279572\n",
      "OBJ: 30660.9148469\n",
      "OBJ: 30463.2576779\n",
      "OBJ: 29754.3651733\n",
      "OBJ: 29587.9541731\n",
      "OBJ: 29584.3966264\n",
      "OBJ: 29567.8520873\n",
      "OBJ: 29564.9371551\n",
      "OBJ: 29564.847073\n",
      "OBJ: 29564.8285369\n",
      "OBJ: 29564.8280996\n",
      "OBJ: 29564.8279309\n",
      "OBJ: 29564.8279258\n",
      "OBJ: 29564.8279248\n",
      "OBJ: 29564.8279248\n",
      "OBJ: 29564.8279248\n",
      "ERROR (ORDINAL)  fold 41: 1.02514619883\n",
      "ERROR (LOGISTIC) fold 41: 1.12748538012\n",
      "ERROR (RIDGE)    fold 41: 1.02631578947\n",
      "OBJ: 31665.9986075\n",
      "OBJ: 30819.3025896\n",
      "OBJ: 29842.4522068\n",
      "OBJ: 29611.4460399\n",
      "OBJ: 29527.7643483\n",
      "OBJ: 29519.5728305\n",
      "OBJ: 29518.4704144\n",
      "OBJ: 29518.4172017\n",
      "OBJ: 29518.4150909\n",
      "OBJ: 29518.4148275\n",
      "OBJ: 29518.4148263\n",
      "OBJ: 29518.4148223\n",
      "OBJ: 29518.4148208\n",
      "OBJ: 29518.4148207\n",
      "OBJ: 29518.4148207\n",
      "ERROR (ORDINAL)  fold 42: 1.05263157895\n",
      "ERROR (LOGISTIC) fold 42: 1.15321637427\n",
      "ERROR (RIDGE)    fold 42: 1.02748538012\n",
      "OBJ: 43219.1337379\n",
      "OBJ: 34118.2560483\n",
      "OBJ: 33279.038781\n",
      "OBJ: 30852.8499381\n",
      "OBJ: 30643.0385699\n",
      "OBJ: 29781.047662\n",
      "OBJ: 29545.4068621\n",
      "OBJ: 29527.0062744\n",
      "OBJ: 29524.3168068\n",
      "OBJ: 29522.9327344\n",
      "OBJ: 29522.8226473\n",
      "OBJ: 29522.8215079\n",
      "OBJ: 29522.821507\n",
      "OBJ: 29522.8215034\n",
      "OBJ: 29522.8215021\n",
      "OBJ: 29522.8215021\n",
      "OBJ: 29522.8215021\n",
      "ERROR (ORDINAL)  fold 43: 1.07192982456\n",
      "ERROR (LOGISTIC) fold 43: 1.1216374269\n",
      "ERROR (RIDGE)    fold 43: 1.04619883041\n",
      "OBJ: 35940.9801486\n",
      "OBJ: 33186.4511722\n",
      "OBJ: 32458.1647451\n",
      "OBJ: 30691.0771111\n",
      "OBJ: 30600.4088814\n",
      "OBJ: 29727.3115376\n",
      "OBJ: 29566.8297888\n",
      "OBJ: 29554.7699291\n",
      "OBJ: 29554.1120293\n",
      "OBJ: 29553.8766485\n",
      "OBJ: 29553.8713284\n",
      "OBJ: 29553.8712933\n",
      "OBJ: 29553.8712424\n",
      "OBJ: 29553.8712397\n",
      "OBJ: 29553.8712395\n",
      "OBJ: 29553.8712393\n",
      "OBJ: 29553.8712393\n",
      "ERROR (ORDINAL)  fold 44: 1.0134502924\n",
      "ERROR (LOGISTIC) fold 44: 1.06023391813\n",
      "ERROR (RIDGE)    fold 44: 1.01228070175\n",
      "OBJ: 31221.1531431\n",
      "OBJ: 30885.8143648\n",
      "OBJ: 29880.8138708\n",
      "OBJ: 29580.7894049\n",
      "OBJ: 29580.0308366\n",
      "OBJ: 29560.7180124\n",
      "OBJ: 29551.5714243\n",
      "OBJ: 29550.1691109\n",
      "OBJ: 29550.136909\n",
      "OBJ: 29550.1366268\n",
      "OBJ: 29550.1353798\n",
      "OBJ: 29550.1349659\n",
      "OBJ: 29550.1349578\n",
      "OBJ: 29550.1349575\n",
      "OBJ: 29550.1349566\n",
      "OBJ: 29550.1349566\n",
      "OBJ: 29550.1349566\n",
      "ERROR (ORDINAL)  fold 45: 1.08771929825\n",
      "ERROR (LOGISTIC) fold 45: 1.09298245614\n",
      "ERROR (RIDGE)    fold 45: 1.06315789474\n",
      "OBJ: 36095.6427172\n",
      "OBJ: 33018.382606\n",
      "OBJ: 31193.3998575\n",
      "OBJ: 29912.1457413\n",
      "OBJ: 29679.1512113\n",
      "OBJ: 29602.7452946\n",
      "OBJ: 29596.7694934\n",
      "OBJ: 29596.328038\n",
      "OBJ: 29596.2939053\n",
      "OBJ: 29596.2923648\n",
      "OBJ: 29596.292159\n",
      "OBJ: 29596.2921564\n",
      "OBJ: 29596.2921563\n",
      "OBJ: 29596.2921563\n",
      "OBJ: 29596.2921563\n",
      "ERROR (ORDINAL)  fold 46: 1.06140350877\n",
      "ERROR (LOGISTIC) fold 46: 1.04035087719\n",
      "ERROR (RIDGE)    fold 46: 1.06315789474\n",
      "OBJ: 34834.1588512\n",
      "OBJ: 33055.1680999\n",
      "OBJ: 30855.4375018\n",
      "OBJ: 29858.7363772\n",
      "OBJ: 29835.6925404\n",
      "OBJ: 29611.4999719\n",
      "OBJ: 29606.2271811\n",
      "OBJ: 29606.1871858\n",
      "OBJ: 29605.161884\n",
      "OBJ: 29605.1521505\n",
      "OBJ: 29605.1521299\n",
      "OBJ: 29605.1521001\n",
      "OBJ: 29605.152099\n",
      "OBJ: 29605.1520989\n",
      "OBJ: 29605.1520989\n",
      "OBJ: 29605.1520989\n",
      "ERROR (ORDINAL)  fold 47: 1.02339181287\n",
      "ERROR (LOGISTIC) fold 47: 1.02514619883\n",
      "ERROR (RIDGE)    fold 47: 1.01286549708\n",
      "OBJ: 42763.3644381\n",
      "OBJ: 38031.4570051\n",
      "OBJ: 34563.8722526\n",
      "OBJ: 32337.2524285\n",
      "OBJ: 31240.137698\n",
      "OBJ: 29863.8001419\n",
      "OBJ: 29568.1598841\n",
      "OBJ: 29556.9608659\n",
      "OBJ: 29555.5685843\n",
      "OBJ: 29554.4304527\n",
      "OBJ: 29554.401526\n",
      "OBJ: 29554.3988233\n",
      "OBJ: 29554.3988195\n",
      "OBJ: 29554.3988014\n",
      "OBJ: 29554.398799\n",
      "OBJ: 29554.398799\n",
      "ERROR (ORDINAL)  fold 48: 1.03684210526\n",
      "ERROR (LOGISTIC) fold 48: 1.07543859649\n",
      "ERROR (RIDGE)    fold 48: 1.00760233918\n",
      "OBJ: 34015.2490883\n",
      "OBJ: 31434.1832284\n",
      "OBJ: 30877.2055768\n",
      "OBJ: 29838.6226416\n",
      "OBJ: 29824.0621702\n",
      "OBJ: 29583.6416761\n",
      "OBJ: 29526.5862822\n",
      "OBJ: 29519.0745482\n",
      "OBJ: 29518.9190393\n",
      "OBJ: 29518.917177\n",
      "OBJ: 29518.8882049\n",
      "OBJ: 29518.8878421\n",
      "OBJ: 29518.8878282\n",
      "OBJ: 29518.8877996\n",
      "OBJ: 29518.8877989\n",
      "OBJ: 29518.8877989\n",
      "ERROR (ORDINAL)  fold 49: 1.01578947368\n",
      "ERROR (LOGISTIC) fold 49: 1.09766081871\n",
      "ERROR (RIDGE)    fold 49: 1.00526315789\n",
      "OBJ: 40167.5432365\n",
      "OBJ: 33197.156287\n",
      "OBJ: 31414.5323958\n",
      "OBJ: 29650.5471509\n",
      "OBJ: 29645.2638307\n",
      "OBJ: 29567.7413357\n",
      "OBJ: 29555.0314782\n",
      "OBJ: 29553.9423148\n",
      "OBJ: 29553.9324463\n",
      "OBJ: 29553.9323786\n",
      "OBJ: 29553.9311081\n",
      "OBJ: 29553.9310984\n",
      "OBJ: 29553.9310983\n",
      "OBJ: 29553.9310978\n",
      "OBJ: 29553.9310977\n",
      "OBJ: 29553.9310977\n",
      "ERROR (ORDINAL)  fold 50: 1.0216374269\n",
      "ERROR (LOGISTIC) fold 50: 1.06315789474\n",
      "ERROR (RIDGE)    fold 50: 1.00760233918\n",
      "\n",
      "MEAN ABSOLUTE ERROR (ORDINAL LOGISTIC):    1.0398128655\n",
      "MEAN ABSOLUTE ERROR (LOGISTIC REGRESSION): 1.08783625731\n",
      "MEAN ABSOLUTE ERROR (RIDGE REGRESSION):    1.02870175439\n",
      "MEAN ABSOLUTE ERROR (ORDINAL LOGISTIC):    0.0221036665162\n",
      "MEAN ABSOLUTE ERROR (LOGISTIC REGRESSION): 0.0276800373377\n",
      "MEAN ABSOLUTE ERROR (RIDGE REGRESSION):    0.0197105833552\n"
     ]
    }
   ],
   "source": [
    "X, y = clusterDF, decadeRank\n",
    "#X -= X.mean()\n",
    "y -= y.min()\n",
    "\n",
    "idx = np.argsort(y)\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "cv = cross_validation.ShuffleSplit(y.size, n_iter=50, test_size=.1, random_state=0)\n",
    "score_logistic = []\n",
    "score_ordinal_logistic = []\n",
    "score_ridge = []\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    #test = train\n",
    "    if not np.all(np.unique(y[train]) == np.unique(y)):\n",
    "        # we need the train set to have all different classes\n",
    "        continue\n",
    "    assert np.all(np.unique(y[train]) == np.unique(y))\n",
    "    train = np.sort(train)\n",
    "    test = np.sort(test)\n",
    "    w, theta = ordinal_logistic_fit(X[train], y[train], verbose=True,\n",
    "                                    solver='TNC')\n",
    "    pred = ordinal_logistic_predict(w, theta, X[test])\n",
    "    # 1/0\n",
    "    s = metrics.mean_absolute_error(y[test], pred)\n",
    "    print('ERROR (ORDINAL)  fold %s: %s' % (i+1, s))\n",
    "    score_ordinal_logistic.append(s)\n",
    "\n",
    "    from sklearn import linear_model\n",
    "    clf = linear_model.LogisticRegression(C=1.)\n",
    "    clf.fit(X[train], y[train])\n",
    "    pred = clf.predict(X[test])\n",
    "    s = metrics.mean_absolute_error(y[test], pred)\n",
    "    print('ERROR (LOGISTIC) fold %s: %s' % (i+1, s))\n",
    "    score_logistic.append(s)\n",
    "\n",
    "    from sklearn import linear_model\n",
    "    clf = linear_model.Ridge(alpha=1.)\n",
    "    clf.fit(X[train], y[train])\n",
    "    pred = np.round(clf.predict(X[test]))\n",
    "    s = metrics.mean_absolute_error(y[test], pred)\n",
    "    print('ERROR (RIDGE)    fold %s: %s' % (i+1, s))\n",
    "    score_ridge.append(s)\n",
    "\n",
    "\n",
    "print()\n",
    "print('MEAN ABSOLUTE ERROR (ORDINAL LOGISTIC):    %s' % np.mean(score_ordinal_logistic))\n",
    "print('MEAN ABSOLUTE ERROR (LOGISTIC REGRESSION): %s' % np.mean(score_logistic))\n",
    "print('MEAN ABSOLUTE ERROR (RIDGE REGRESSION):    %s' % np.mean(score_ridge))\n",
    "print('ERROR Standard Dev (ORDINAL LOGISTIC):    %s' % np.std(score_ordinal_logistic))\n",
    "print('ERROR Standard Dev (LOGISTIC REGRESSION): %s' % np.std(score_logistic))\n",
    "print('ERROR Standard Dev (RIDGE REGRESSION):    %s' % np.std(score_ridge))\n",
    "# print('Chance level is at %s' % (1. / np.unique(y).size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
